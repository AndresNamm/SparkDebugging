

[This is the best tutorial on how to size your spark executors based on the size of your cluster](https://www.c2fo.io/c2fo/spark/aws/emr/2016/07/06/apache-spark-config-cheatsheet/)


I have created a function which somewhat tries to give you the best configuration based on the logic obtained from this article. 

